{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miamkimhongil92\u001b[0m (\u001b[33miamkimhongil92-lumenasoft\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/hanghae99_plusAI_2/8_basic/wandb/run-20250208_161911-d6qcucw2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/d6qcucw2' target=\"_blank\">rank 256</a></strong> to <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/d6qcucw2' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/d6qcucw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dfcb51c0964b9c9c3ae10412c6360a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52abc3fa2d4d4b39a970f52702d3a29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-e270777bb989ac86.parquet:   0%|          | 0.00/3.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3496d1ad2d324caa9dc6a65cb5fa783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0df5c8636c428f8e4ba86532bb3aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd84476fb5a645c8a2c7220a7144c8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e93984a89614f919e1f738708bc15be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b700ce9ddc7497c8ff3119aac9fa442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ceff9d7dc34e4a97204bf45b4351c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc01927dfd8a4618aa73a31117f960cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/2d/51/2d51352256ba577724ec53b247175bd0928dfc5387e98f45a2f3eab954c26eaf/a5223ae6f3c26c6d90003f96a6bcd9a4aaaef0d36fca6469112efeeb985f2842?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1739035158&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTAzNTE1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZC81MS8yZDUxMzUyMjU2YmE1Nzc3MjRlYzUzYjI0NzE3NWJkMDkyOGRmYzUzODdlOThmNDVhMmYzZWFiOTU0YzI2ZWFmL2E1MjIzYWU2ZjNjMjZjNmQ5MDAwM2Y5NmE2YmNkOWE0YWFhZWYwZDM2ZmNhNjQ2OTExMmVmZWViOTg1ZjI4NDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=plpi3VUxXHZtX5mA9JMUSpwvfs0DSohtdHsnHH8MRDFA09Sr58u64KEHxu0ppX5GRL5UvAMiPH7nsCL8BiEH1H8C8P8eUyDkRG3NMoZwNkKXJ9njIL7GO2l56bpHGwhnlcgUmI8vtvaQc73iIvDa1aHWBLueFeVX1j6DNXeuCfXie8zkP%7EswxlPlRVVjp%7Es4GNLC99WR6W8TrpGhYAGMArYUPmn1xSSQL-CGFUzQI40t2tVQP8S4TfTjPHM9Yjw6Wb7xwLAv2U6-xzdXs-eXohWcIx7f6pE4jkKlgSGPig3%7Emy0wJ5lAcz7iNRhoWZHQn-fkc6sW5-WKhq1VtsOstA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bb0f21b3dd406bbb676e99e8dd07ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  55%|#####5    | 367M/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a64398a0a044b65a7c5f704cccea7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/662M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9087a7a87241445384223433b1a68c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5747fdae4b64cafb98cba783966ecd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16017 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d692387442584903a5007b1a1ab87655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12015' max='12015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12015/12015 40:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.744400</td>\n",
       "      <td>1.565788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.617500</td>\n",
       "      <td>1.476991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.513600</td>\n",
       "      <td>1.427202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.442200</td>\n",
       "      <td>1.388033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.463400</td>\n",
       "      <td>1.355168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.415400</td>\n",
       "      <td>1.331674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.407500</td>\n",
       "      <td>1.307288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.377800</td>\n",
       "      <td>1.292418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.310600</td>\n",
       "      <td>1.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.299900</td>\n",
       "      <td>1.264449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.285600</td>\n",
       "      <td>1.252551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.306400</td>\n",
       "      <td>1.238943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.265500</td>\n",
       "      <td>1.231244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.229639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.262800</td>\n",
       "      <td>1.214629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.249600</td>\n",
       "      <td>1.207610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.227900</td>\n",
       "      <td>1.200338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>1.195884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.215100</td>\n",
       "      <td>1.190196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.219600</td>\n",
       "      <td>1.186380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.205700</td>\n",
       "      <td>1.182626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>1.179772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.207800</td>\n",
       "      <td>1.179110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.176200</td>\n",
       "      <td>1.177620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Alloc: 25.2 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "lora_r: int = 256            # 행렬의 랭크\n",
    "lora_dropout: float = 0.1  # LoRA parameter에 적용할 dropout 확률\n",
    "lora_alpha: int = 32       # LoRA parameter인 $A, B$ 행렬을 scaling할 때 사용하는 값\n",
    "\n",
    "wandb.init(project='Hanghae99_8basic', name=f\"rank {lora_r}\")\n",
    "\n",
    "\n",
    "# 데이터셋을 90%:10% 비율로 나누어 train과 validation 데이터셋 생성\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "split_data = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = split_data['train']\n",
    "eval_dataset = split_data['test']\n",
    "\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "target_modules = set()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        names = name.split('.')\n",
    "        target_modules.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "if \"lm_head\" in target_modules:  # needed for 16-bit\n",
    "    target_modules.remove(\"lm_head\")\n",
    "\n",
    "target_modules = list(target_modules)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "\n",
    "# 'formatting_prompts_func'는 데이터셋 예시를 입력 받아, 'Instruction'과 'Output'을 적절한 형식으로 변환합니다.\n",
    "# 각 'Instruction'과 'Output' 쌍을 연결하여 모델이 이를 처리할 수 있도록 합니다.\n",
    "# 주어진 형식: '### Question: [Instruction]\\n### Answer: [Output]'\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \" ### Answer:\"\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "# 콜백 클래스 정의\n",
    "class WandbLoggingCallback(TrainerCallback):\n",
    "    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # train loss 기록\n",
    "            if \"loss\" in logs:\n",
    "                wandb.log({\"train/loss\": logs[\"loss\"], \"step\": state.global_step})\n",
    "\n",
    "            # validation 평가 및 loss 기록 (평가 주기에 따라 실행됨)\n",
    "            if \"eval_loss\" in logs:\n",
    "                wandb.log({\"eval/loss\": logs[\"eval_loss\"], \"step\": state.global_step})\n",
    "\n",
    "\n",
    "# TrainingArguments로 로그 빈도 및 기타 학습 설정 관리\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/clm-instruction-tuning\",  # 출력 디렉터리 설정\n",
    "    logging_steps=500,                         # 로그 빈도 설정 (매 100 스텝마다 로그 기록)\n",
    "    evaluation_strategy=\"steps\",               # 평가 전략을 'steps'로 설정\n",
    "    eval_steps=500,                            # 평가 빈도 설정\n",
    "    save_steps=0,                              # 저장 비활성화\n",
    "    save_total_limit=0,                        # 체크포인트 개수 제한 없음\n",
    "    save_strategy=\"no\",                        # 'no'로 설정하여 저장 완전 비활성화\n",
    "    per_device_train_batch_size=4,      # 학습 시 배치 크기 설정\n",
    "    per_device_eval_batch_size=4        # 평가 시 배치 크기 설정\n",
    ")\n",
    "\n",
    "# Trainer 생성\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=training_args,                         # TrainingArguments로 설정 전달\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    callbacks=[WandbLoggingCallback()]          # 콜백 추가\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "max_memory_allocated_gb = round(torch.cuda.max_memory_allocated(0) / 1024**3, 1)\n",
    "print('Max Alloc:', max_memory_allocated_gb, 'GB')\n",
    "wandb.log({\"max_memory_allocated_gb\": max_memory_allocated_gb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
