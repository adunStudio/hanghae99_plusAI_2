{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miamkimhongil92\u001b[0m (\u001b[33miamkimhongil92-lumenasoft\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/hanghae99_plusAI_2/8_basic/wandb/run-20250208_161400-lem6en0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k' target=\"_blank\">rank 8</a></strong> to <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ebc4f9c6574dc29fe51eb056c6fcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16017 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8058092d1004693998a3482431dde09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12015' max='12015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12015/12015 32:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.752700</td>\n",
       "      <td>1.549249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.586900</td>\n",
       "      <td>1.470563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.518100</td>\n",
       "      <td>1.418229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.502600</td>\n",
       "      <td>1.382531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.476200</td>\n",
       "      <td>1.353905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>1.330733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.409900</td>\n",
       "      <td>1.307001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.419700</td>\n",
       "      <td>1.289413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.357600</td>\n",
       "      <td>1.276621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.305800</td>\n",
       "      <td>1.262795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.314200</td>\n",
       "      <td>1.248557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>1.237880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>1.228788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>1.217453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.282200</td>\n",
       "      <td>1.212384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.285300</td>\n",
       "      <td>1.203607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.236700</td>\n",
       "      <td>1.199770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.220100</td>\n",
       "      <td>1.195261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.241100</td>\n",
       "      <td>1.190161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.212300</td>\n",
       "      <td>1.184125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.238300</td>\n",
       "      <td>1.182029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.206800</td>\n",
       "      <td>1.179586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.229800</td>\n",
       "      <td>1.177336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.176900</td>\n",
       "      <td>1.176470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Alloc: 23.4 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "lora_r: int = 8            # í–‰ë ¬ì˜ ë­í¬\n",
    "lora_dropout: float = 0.1  # LoRA parameterì— ì ìš©í•  dropout í™•ë¥ \n",
    "lora_alpha: int = 32       # LoRA parameterì¸ $A, B$ í–‰ë ¬ì„ scalingí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê°’\n",
    "\n",
    "wandb.init(project='Hanghae99_8basic', name=f\"rank {lora_r}\")\n",
    "\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ 90%:10% ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ì–´ trainê³¼ validation ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "split_data = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = split_data['train']\n",
    "eval_dataset = split_data['test']\n",
    "\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "target_modules = set()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        names = name.split('.')\n",
    "        target_modules.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "if \"lm_head\" in target_modules:  # needed for 16-bit\n",
    "    target_modules.remove(\"lm_head\")\n",
    "\n",
    "target_modules = list(target_modules)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "\n",
    "# 'formatting_prompts_func'ëŠ” ë°ì´í„°ì…‹ ì˜ˆì‹œë¥¼ ì…ë ¥ ë°›ì•„, 'Instruction'ê³¼ 'Output'ì„ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "# ê° 'Instruction'ê³¼ 'Output' ìŒì„ ì—°ê²°í•˜ì—¬ ëª¨ë¸ì´ ì´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "# ì£¼ì–´ì§„ í˜•ì‹: '### Question: [Instruction]\\n### Answer: [Output]'\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \" ### Answer:\"\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "# ì½œë°± í´ë˜ìŠ¤ ì •ì˜\n",
    "class WandbLoggingCallback(TrainerCallback):\n",
    "    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # train loss ê¸°ë¡\n",
    "            if \"loss\" in logs:\n",
    "                wandb.log({\"train/loss\": logs[\"loss\"], \"step\": state.global_step})\n",
    "\n",
    "            # validation í‰ê°€ ë° loss ê¸°ë¡ (í‰ê°€ ì£¼ê¸°ì— ë”°ë¼ ì‹¤í–‰ë¨)\n",
    "            if \"eval_loss\" in logs:\n",
    "                wandb.log({\"eval/loss\": logs[\"eval_loss\"], \"step\": state.global_step})\n",
    "\n",
    "\n",
    "# TrainingArgumentsë¡œ ë¡œê·¸ ë¹ˆë„ ë° ê¸°íƒ€ í•™ìŠµ ì„¤ì • ê´€ë¦¬\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/clm-instruction-tuning\",  # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    logging_steps=500,                         # ë¡œê·¸ ë¹ˆë„ ì„¤ì • (ë§¤ 100 ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸ ê¸°ë¡)\n",
    "    evaluation_strategy=\"steps\",               # í‰ê°€ ì „ëµì„ 'steps'ë¡œ ì„¤ì •\n",
    "    eval_steps=500,                            # í‰ê°€ ë¹ˆë„ ì„¤ì •\n",
    "    save_steps=0,                              # ì €ì¥ ë¹„í™œì„±í™”\n",
    "    save_total_limit=0,                        # ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜ ì œí•œ ì—†ìŒ\n",
    "    save_strategy=\"no\",                        # 'no'ë¡œ ì„¤ì •í•˜ì—¬ ì €ì¥ ì™„ì „ ë¹„í™œì„±í™”\n",
    "    per_device_train_batch_size=4,      # í•™ìŠµ ì‹œ ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
    "    per_device_eval_batch_size=4        # í‰ê°€ ì‹œ ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
    ")\n",
    "\n",
    "# Trainer ìƒì„±\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=training_args,                         # TrainingArgumentsë¡œ ì„¤ì • ì „ë‹¬\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    callbacks=[WandbLoggingCallback()]          # ì½œë°± ì¶”ê°€\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "max_memory_allocated_gb = round(torch.cuda.max_memory_allocated(0) / 1024**3, 1)\n",
    "print('Max Alloc:', max_memory_allocated_gb, 'GB')\n",
    "wandb.log({\"max_memory_allocated_gb\": max_memory_allocated_gb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
