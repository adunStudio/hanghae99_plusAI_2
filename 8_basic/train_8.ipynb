{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miamkimhongil92\u001b[0m (\u001b[33miamkimhongil92-lumenasoft\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/hanghae99_plusAI_2/8_basic/wandb/run-20250208_161400-lem6en0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k' target=\"_blank\">rank 8</a></strong> to <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k' target=\"_blank\">https://wandb.ai/iamkimhongil92-lumenasoft/Hanghae99_8basic/runs/lem6en0k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ebc4f9c6574dc29fe51eb056c6fcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16017 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8058092d1004693998a3482431dde09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12015' max='12015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12015/12015 32:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.752700</td>\n",
       "      <td>1.549249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.586900</td>\n",
       "      <td>1.470563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.518100</td>\n",
       "      <td>1.418229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.502600</td>\n",
       "      <td>1.382531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.476200</td>\n",
       "      <td>1.353905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>1.330733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.409900</td>\n",
       "      <td>1.307001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.419700</td>\n",
       "      <td>1.289413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.357600</td>\n",
       "      <td>1.276621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.305800</td>\n",
       "      <td>1.262795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.314200</td>\n",
       "      <td>1.248557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>1.237880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>1.228788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>1.217453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.282200</td>\n",
       "      <td>1.212384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.285300</td>\n",
       "      <td>1.203607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.236700</td>\n",
       "      <td>1.199770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.220100</td>\n",
       "      <td>1.195261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.241100</td>\n",
       "      <td>1.190161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.212300</td>\n",
       "      <td>1.184125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.238300</td>\n",
       "      <td>1.182029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.206800</td>\n",
       "      <td>1.179586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.229800</td>\n",
       "      <td>1.177336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.176900</td>\n",
       "      <td>1.176470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Alloc: 23.4 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "lora_r: int = 8            # ÌñâÎ†¨Ïùò Îû≠ÌÅ¨\n",
    "lora_dropout: float = 0.1  # LoRA parameterÏóê Ï†ÅÏö©Ìï† dropout ÌôïÎ•†\n",
    "lora_alpha: int = 32       # LoRA parameterÏù∏ $A, B$ ÌñâÎ†¨ÏùÑ scalingÌï† Îïå ÏÇ¨Ïö©ÌïòÎäî Í∞í\n",
    "\n",
    "wandb.init(project='Hanghae99_8basic', name=f\"rank {lora_r}\")\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ 90%:10% ÎπÑÏú®Î°ú ÎÇòÎàÑÏñ¥ trainÍ≥º validation Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "split_data = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = split_data['train']\n",
    "eval_dataset = split_data['test']\n",
    "\n",
    "\n",
    "# Î™®Îç∏Í≥º ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "target_modules = set()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        names = name.split('.')\n",
    "        target_modules.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "if \"lm_head\" in target_modules:  # needed for 16-bit\n",
    "    target_modules.remove(\"lm_head\")\n",
    "\n",
    "target_modules = list(target_modules)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "\n",
    "# 'formatting_prompts_func'Îäî Îç∞Ïù¥ÌÑ∞ÏÖã ÏòàÏãúÎ•º ÏûÖÎ†• Î∞õÏïÑ, 'Instruction'Í≥º 'Output'ÏùÑ Ï†ÅÏ†àÌïú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.\n",
    "# Í∞Å 'Instruction'Í≥º 'Output' ÏåçÏùÑ Ïó∞Í≤∞ÌïòÏó¨ Î™®Îç∏Ïù¥ Ïù¥Î•º Ï≤òÎ¶¨Ìï† Ïàò ÏûàÎèÑÎ°ù Ìï©ÎãàÎã§.\n",
    "# Ï£ºÏñ¥ÏßÑ ÌòïÏãù: '### Question: [Instruction]\\n### Answer: [Output]'\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \" ### Answer:\"\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "# ÏΩúÎ∞± ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class WandbLoggingCallback(TrainerCallback):\n",
    "    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # train loss Í∏∞Î°ù\n",
    "            if \"loss\" in logs:\n",
    "                wandb.log({\"train/loss\": logs[\"loss\"], \"step\": state.global_step})\n",
    "\n",
    "            # validation ÌèâÍ∞Ä Î∞è loss Í∏∞Î°ù (ÌèâÍ∞Ä Ï£ºÍ∏∞Ïóê Îî∞Îùº Ïã§ÌñâÎê®)\n",
    "            if \"eval_loss\" in logs:\n",
    "                wandb.log({\"eval/loss\": logs[\"eval_loss\"], \"step\": state.global_step})\n",
    "\n",
    "\n",
    "# TrainingArgumentsÎ°ú Î°úÍ∑∏ ÎπàÎèÑ Î∞è Í∏∞ÌÉÄ ÌïôÏäµ ÏÑ§Ï†ï Í¥ÄÎ¶¨\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/clm-instruction-tuning\",  # Ï∂úÎ†• ÎîîÎ†âÌÑ∞Î¶¨ ÏÑ§Ï†ï\n",
    "    logging_steps=500,                         # Î°úÍ∑∏ ÎπàÎèÑ ÏÑ§Ï†ï (Îß§ 100 Ïä§ÌÖùÎßàÎã§ Î°úÍ∑∏ Í∏∞Î°ù)\n",
    "    evaluation_strategy=\"steps\",               # ÌèâÍ∞Ä Ï†ÑÎûµÏùÑ 'steps'Î°ú ÏÑ§Ï†ï\n",
    "    eval_steps=500,                            # ÌèâÍ∞Ä ÎπàÎèÑ ÏÑ§Ï†ï\n",
    "    save_steps=0,                              # Ï†ÄÏû• ÎπÑÌôúÏÑ±Ìôî\n",
    "    save_total_limit=0,                        # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Í∞úÏàò Ï†úÌïú ÏóÜÏùå\n",
    "    save_strategy=\"no\",                        # 'no'Î°ú ÏÑ§Ï†ïÌïòÏó¨ Ï†ÄÏû• ÏôÑÏ†Ñ ÎπÑÌôúÏÑ±Ìôî\n",
    "    per_device_train_batch_size=4,      # ÌïôÏäµ Ïãú Î∞∞Ïπò ÌÅ¨Í∏∞ ÏÑ§Ï†ï\n",
    "    per_device_eval_batch_size=4        # ÌèâÍ∞Ä Ïãú Î∞∞Ïπò ÌÅ¨Í∏∞ ÏÑ§Ï†ï\n",
    ")\n",
    "\n",
    "# Trainer ÏÉùÏÑ±\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=training_args,                         # TrainingArgumentsÎ°ú ÏÑ§Ï†ï Ï†ÑÎã¨\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    callbacks=[WandbLoggingCallback()]          # ÏΩúÎ∞± Ï∂îÍ∞Ä\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "max_memory_allocated_gb = round(torch.cuda.max_memory_allocated(0) / 1024**3, 1)\n",
    "print('Max Alloc:', max_memory_allocated_gb, 'GB')\n",
    "wandb.log({\"max_memory_allocated_gb\": max_memory_allocated_gb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
