import json
from sklearn.model_selection import train_test_split
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import Dataset, DatasetDict
from transformers.trainer_utils import get_last_checkpoint
from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM
from transformers import EarlyStoppingCallback
import evaluate
import wandb

# ğŸ”¹ 1. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„
# corpus.json íŒŒì¼ ë¡œë“œ
with open("corpus.json", "r", encoding="utf-8") as file:
    corpus_data = json.load(file)

# ğŸ”¹ 2. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
train_data, val_data = train_test_split(corpus_data, test_size=0.2, random_state=42)

# ğŸ”¹ 3. ë°ì´í„°ì…‹ ìƒì„±
dataset = DatasetDict({
    "train": Dataset.from_list(train_data),
    "validation": Dataset.from_list(val_data)
})

# ğŸ”¹ 4. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •
#model_name = "meta-llama/Llama-3.2-3B-Instruct"
model_name = "google/gemma-2-2b-it"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# ğŸ”¹ 5. ë°ì´í„° í¬ë§·íŒ… í•¨ìˆ˜
def formatting_prompts_func(example):
    return f"### Instruction: {example['input']}\n### Response: {example['output']}"

# ğŸ”¹ 6. ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •
response_template = "### Response:"
collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)

# ğŸ”¹ 7. W&B ì„¤ì •
wandb.init(project="llama-instruction-tuning", name="llama-3b-instruct")

# ğŸ”¹ 8. ROUGE ë° BLEU ë©”íŠ¸ë¦­ ë¡œë“œ
rouge_metric = evaluate.load("rouge")
bleu_metric = evaluate.load("bleu")

# ğŸ”¹ 9. í‰ê°€ í•¨ìˆ˜ ì •ì˜
def compute_metrics(eval_preds):
    predictions, labels = eval_preds
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # ğŸ”¸ BLEU ì ìˆ˜ ê³„ì‚°
    predictions = [pred.split() for pred in decoded_preds]
    references = [[label.split()] for label in decoded_labels]
    bleu = bleu_metric.compute(predictions=predictions, references=references)

    # ğŸ”¸ ROUGE ì ìˆ˜ ê³„ì‚°
    rouge = rouge_metric.compute(
        predictions=decoded_preds,
        references=decoded_labels,
        use_stemmer=True
    )

    # ğŸ”¸ W&Bë¡œ ë©”íŠ¸ë¦­ ê¸°ë¡
    wandb.log({
        "bleu_score": bleu["bleu"],
        "rouge1": rouge["rouge1"].mid.fmeasure,
        "rouge2": rouge["rouge2"].mid.fmeasure,
        "rougeL": rouge["rougeL"].mid.fmeasure,
    })

    return {
        "bleu_score": bleu["bleu"],
        "rouge1": rouge["rouge1"].mid.fmeasure,
        "rouge2": rouge["rouge2"].mid.fmeasure,
        "rougeL": rouge["rougeL"].mid.fmeasure,
    }

#output_dir = "./finetuned_llama"
output_dir = "./finetuned_gemma"

# ğŸ”¹ 10. SFT Trainer ì„¤ì •
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    args=SFTConfig(
        output_dir=output_dir,
        per_device_train_batch_size=4,
        per_device_eval_batch_size=4,
        num_train_epochs=10,
        logging_dir="./logs",
        logging_steps=50,
        save_steps=100,
        report_to=["wandb"]  # W&Bì— ë¡œê·¸ ì „ì†¡
    ),
    formatting_func=formatting_prompts_func,
    data_collator=collator,
    compute_metrics=compute_metrics,  # ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
)


trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))

# ğŸ”¹ 11. í•™ìŠµ ì‹œì‘
last_checkpoint = get_last_checkpoint(output_dir)

if last_checkpoint is None:
    trainer.train()
else:
    trainer.train(resume_from_checkpoint=last_checkpoint)


wandb.finish()