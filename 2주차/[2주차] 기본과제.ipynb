{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Last word prediction dataset 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HOdhoBVA1zcu",
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:00.732391Z",
     "start_time": "2024-12-24T11:26:53.606238Z"
    }
   },
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from numpy.ma.extras import average\n",
    "from torch.nn.functional import dropout\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "  max_len= 400\n",
    "  texts, labels = [], []\n",
    "  for row in batch:\n",
    "    # 라벨을 감정이 아닌 각 텍스트의 뒷자리 단어(토큰) 2개로 변경\n",
    "    tokenizer_output = tokenizer(row['text'], truncation=True, max_length=max_len)\n",
    "    labels.append(tokenizer_output.input_ids[-2])\n",
    "    texts.append(torch.LongTensor(tokenizer_output.input_ids[:-2]))\n",
    "\n",
    "  # 패딩 처리(길이가 맞지 않는 경우를 위해)\n",
    "  texts = pad_sequence(texts, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "  labels = torch.LongTensor(labels)\n",
    "\n",
    "  return texts, labels\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    ds['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    ds['test'], batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kimhongil/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": "# [MY CODE] Shape와 입력/출력 확인(빈도 등)",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ds['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:00.748560Z",
     "start_time": "2024-12-24T11:27:00.744876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    inputs, labels = batch  # DataLoader에서 배치 추출\n",
    "    print(f\"입력 텍스트 (input_ids) shape: {inputs.shape}\")\n",
    "    print(f\"출력 라벨 (labels) shape: {labels.shape}\")\n",
    "    break  # 첫 번째 배치만 확인"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:01.784644Z",
     "start_time": "2024-12-24T11:27:01.751466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텍스트 (input_ids) shape: torch.Size([64, 398])\n",
      "출력 라벨 (labels) shape: torch.Size([64])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    inputs, labels = batch  # DataLoader에서 배치 추출\n",
    "\n",
    "    # 첫 번째 샘플만 확인\n",
    "    idx = 0\n",
    "    first_input = inputs[idx]\n",
    "    first_label = labels[idx]\n",
    "\n",
    "    # 입력 텍스트 디코딩 (토큰 단위)\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(first_input)\n",
    "    decoded_text = tokenizer.decode(first_input)\n",
    "\n",
    "    # 라벨 디코딩 (정답 토큰 ID를 텍스트로 변환)\n",
    "    label_token = tokenizer.convert_ids_to_tokens([first_label])  # 라벨은 단일 토큰\n",
    "    label_text = tokenizer.decode([first_label])  # 라벨을 문장으로 변환\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"입력 텍스트 (토큰):\", decoded_tokens)\n",
    "    print(\"입력 텍스트 (문장):\", decoded_text)\n",
    "    print(\"출력 라벨 (토큰):\", label_token)\n",
    "    print(\"출력 라벨 (문장):\", label_text)\n",
    "\n",
    "    break  # 첫 번째 배치만 확인"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:01.821787Z",
     "start_time": "2024-12-24T11:27:01.788391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텍스트 (토큰): ['[CLS]', 'i', 'rented', 'i', 'am', 'curious', '-', 'yellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it', 'was', 'first', 'released', 'in', '1967', '.', 'i', 'also', 'heard', 'that', 'at', 'first', 'it', 'was', 'seized', 'by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever', 'tried', 'to', 'enter', 'this', 'country', ',', 'therefore', 'being', 'a', 'fan', 'of', 'films', 'considered', '\"', 'controversial', '\"', 'i', 'really', 'had', 'to', 'see', 'this', 'for', 'myself', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'plot', 'is', 'centered', 'around', 'a', 'young', 'swedish', 'drama', 'student', 'named', 'lena', 'who', 'wants', 'to', 'learn', 'everything', 'she', 'can', 'about', 'life', '.', 'in', 'particular', 'she', 'wants', 'to', 'focus', 'her', 'attention', '##s', 'to', 'making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average', 'sw', '##ede', 'thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'vietnam', 'war', 'and', 'race', 'issues', 'in', 'the', 'united', 'states', '.', 'in', 'between', 'asking', 'politicians', 'and', 'ordinary', 'den', '##ize', '##ns', 'of', 'stockholm', 'about', 'their', 'opinions', 'on', 'politics', ',', 'she', 'has', 'sex', 'with', 'her', 'drama', 'teacher', ',', 'classmates', ',', 'and', 'married', 'men', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'what', 'kills', 'me', 'about', 'i', 'am', 'curious', '-', 'yellow', 'is', 'that', '40', 'years', 'ago', ',', 'this', 'was', 'considered', 'pornographic', '.', 'really', ',', 'the', 'sex', 'and', 'nu', '##dity', 'scenes', 'are', 'few', 'and', 'far', 'between', ',', 'even', 'then', 'it', \"'\", 's', 'not', 'shot', 'like', 'some', 'cheap', '##ly', 'made', 'porn', '##o', '.', 'while', 'my', 'country', '##men', 'mind', 'find', 'it', 'shocking', ',', 'in', 'reality', 'sex', 'and', 'nu', '##dity', 'are', 'a', 'major', 'staple', 'in', 'swedish', 'cinema', '.', 'even', 'ing', '##mar', 'bergman', ',', 'arguably', 'their', 'answer', 'to', 'good', 'old', 'boy', 'john', 'ford', ',', 'had', 'sex', 'scenes', 'in', 'his', 'films', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'do', 'com', '##men', '##d', 'the', 'filmmakers', 'for', 'the', 'fact', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money', 'to', 'be', 'shown', 'in', 'pornographic', 'theaters', 'in', 'america', '.', 'i', 'am', 'curious', '-', 'yellow', 'is', 'a', 'good', 'film', 'for', 'anyone', 'wanting', 'to', 'study', 'the', 'meat', 'and', 'potatoes', '(', 'no', 'pun', 'intended', ')', 'of', 'swedish', 'cinema', '.', 'but', 'really', ',', 'this', 'film', 'doesn', \"'\", 't', 'have', 'much', 'of', 'a', 'plot', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "입력 텍스트 (문장): [CLS] i rented i am curious - yellow from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at first it was seized by u. s. customs if it ever tried to enter this country, therefore being a fan of films considered \" controversial \" i really had to see this for myself. < br / > < br / > the plot is centered around a young swedish drama student named lena who wants to learn everything she can about life. in particular she wants to focus her attentions to making some sort of documentary on what the average swede thought about certain political issues such as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it ' s not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman, arguably their answer to good old boy john ford, had sex scenes in his films. < br / > < br / > i do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in america. i am curious - yellow is a good film for anyone wanting to study the meat and potatoes ( no pun intended ) of swedish cinema. but really, this film doesn ' t have much of a plot [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "출력 라벨 (토큰): ['.']\n",
      "출력 라벨 (문장): .\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_labels = []  # 모든 라벨을 저장할 리스트\n",
    "label_counts = Counter(all_labels)\n",
    "decoded_labels = tokenizer.convert_ids_to_tokens(list(label_counts.keys()))\n",
    "\n",
    "# DataLoader에서 배치 순회\n",
    "for batch in train_loader:\n",
    "    inputs, labels = batch  # 라벨 추출\n",
    "    all_labels.extend(labels.tolist())  # 리스트로 변환 후 확장\n",
    "\n",
    "# 라벨의 유니크 값 확인\n",
    "unique_labels = set(all_labels)\n",
    "print(\"유니크 라벨 목록:\", unique_labels)\n",
    "print(f\"총 유니크 라벨 개수: {len(unique_labels)}\")\n",
    "\n",
    "\n",
    "label_counts = Counter(all_labels)\n",
    "top_10_labels = label_counts.most_common(10)  # 상위 10개 라벨\n",
    "decoded_top_10 = tokenizer.convert_ids_to_tokens([item[0] for item in top_10_labels])\n",
    "\n",
    "for word, (token_id, count) in zip(decoded_top_10, top_10_labels):\n",
    "    print(f\"라벨: {word} (토큰 ID: {token_id}) - 등장 횟수: {count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:09.993883Z",
     "start_time": "2024-12-24T11:27:02.185912Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m decoded_labels \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mconvert_ids_to_tokens(\u001B[38;5;28mlist\u001B[39m(label_counts\u001B[38;5;241m.\u001B[39mkeys()))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# DataLoader에서 배치 순회\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m      9\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m batch  \u001B[38;5;66;03m# 라벨 추출\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     all_labels\u001B[38;5;241m.\u001B[39mextend(labels\u001B[38;5;241m.\u001B[39mtolist())  \u001B[38;5;66;03m# 리스트로 변환 후 확장\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "Cell \u001B[0;32mIn[78], line 17\u001B[0m, in \u001B[0;36mcollate_fn\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m texts, labels \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[1;32m     16\u001B[0m   \u001B[38;5;66;03m# 라벨을 감정이 아닌 각 텍스트의 뒷자리 단어(토큰) 2개로 변경\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m   tokenizer_output \u001B[38;5;241m=\u001B[39m tokenizer(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m], truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39mmax_len)\n\u001B[1;32m     18\u001B[0m   labels\u001B[38;5;241m.\u001B[39mappend(tokenizer_output\u001B[38;5;241m.\u001B[39minput_ids[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m     19\u001B[0m   texts\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mLongTensor(tokenizer_output\u001B[38;5;241m.\u001B[39minput_ids[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3016\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3014\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   3015\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 3016\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[1;32m   3017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3018\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3126\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[1;32m   3104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[1;32m   3105\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[1;32m   3106\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3123\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3124\u001B[0m     )\n\u001B[1;32m   3125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m   3127\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   3128\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   3129\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   3130\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   3131\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   3132\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   3133\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   3134\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   3135\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   3136\u001B[0m         padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m   3137\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   3138\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   3139\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   3140\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   3141\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   3142\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   3143\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   3144\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   3145\u001B[0m         split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[1;32m   3146\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3147\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3202\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3192\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[1;32m   3193\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[1;32m   3194\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   3195\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3199\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3200\u001B[0m )\n\u001B[0;32m-> 3202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encode_plus(\n\u001B[1;32m   3203\u001B[0m     text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   3204\u001B[0m     text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   3205\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   3206\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m   3207\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m   3208\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   3209\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   3210\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   3211\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   3212\u001B[0m     padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m   3213\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   3214\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   3215\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   3216\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   3217\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   3218\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   3219\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   3220\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   3221\u001B[0m     split_special_tokens\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit_special_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_special_tokens),\n\u001B[1;32m   3222\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3223\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:603\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._encode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_encode_plus\u001B[39m(\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    581\u001B[0m     text: Union[TextInput, PreTokenizedInput],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    601\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BatchEncoding:\n\u001B[1;32m    602\u001B[0m     batched_input \u001B[38;5;241m=\u001B[39m [(text, text_pair)] \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;28;01melse\u001B[39;00m [text]\n\u001B[0;32m--> 603\u001B[0m     batched_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[1;32m    604\u001B[0m         batched_input,\n\u001B[1;32m    605\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m    606\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m    607\u001B[0m         padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m    608\u001B[0m         truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m    609\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m    610\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m    611\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m    612\u001B[0m         padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m    613\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m    614\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m    615\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m    616\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m    617\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m    618\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m    619\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m    620\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    621\u001B[0m         split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[1;32m    622\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    623\u001B[0m     )\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001B[39;00m\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_overflowing_tokens:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:529\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001B[0m\n\u001B[1;32m    526\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m!=\u001B[39m split_special_tokens:\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m=\u001B[39m split_special_tokens\n\u001B[0;32m--> 529\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_batch(\n\u001B[1;32m    530\u001B[0m     batch_text_or_text_pairs,\n\u001B[1;32m    531\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m    532\u001B[0m     is_pretokenized\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m    533\u001B[0m )\n\u001B[1;32m    535\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[1;32m    541\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[1;32m    543\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[1;32m    553\u001B[0m ]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:09.995975Z",
     "start_time": "2024-12-24T11:14:56.798972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "max_len = 400\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-FshZcTZBQ2"
   },
   "source": "## 주어진 코드"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MBlMVMZcRAxv",
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.003711Z",
     "start_time": "2024-12-24T11:14:56.804590Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, input_dim, d_model):\n",
    "    super().__init__()\n",
    "\n",
    "    self.input_dim = input_dim\n",
    "    self.d_model = d_model\n",
    "\n",
    "    self.wq = nn.Linear(input_dim, d_model)\n",
    "    self.wk = nn.Linear(input_dim, d_model)\n",
    "    self.wv = nn.Linear(input_dim, d_model)\n",
    "    self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    q, k, v = self.wq(x), self.wk(x), self.wv(x)\n",
    "    score = torch.matmul(q, k.transpose(-1, -2)) # (B, S, D) * (B, D, S) = (B, S, S)\n",
    "    score = score / sqrt(self.d_model)\n",
    "\n",
    "    if mask is not None:\n",
    "      score = score + (mask * -1e9)\n",
    "\n",
    "    score = self.softmax(score)\n",
    "    result = torch.matmul(score, v)\n",
    "    result = self.dense(result)\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VZHPCn9AS5Gp",
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.004698Z",
     "start_time": "2024-12-24T11:14:57.145606Z"
    }
   },
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "  def __init__(self, input_dim, d_model, dff):\n",
    "    super().__init__()\n",
    "\n",
    "    self.input_dim = input_dim\n",
    "    self.d_model = d_model\n",
    "    self.dff = dff\n",
    "\n",
    "    self.sa = SelfAttention(input_dim, d_model)\n",
    "    self.ffn = nn.Sequential(\n",
    "      nn.Linear(d_model, dff),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(dff, d_model)\n",
    "    )\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    x = self.sa(x, mask)\n",
    "    x = self.ffn(x)\n",
    "\n",
    "    return x"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1723896343031,
     "user": {
      "displayName": "조승혁",
      "userId": "15759752471844115325"
     },
     "user_tz": -540
    },
    "id": "Uf_jMQWDUR79",
    "outputId": "534712be-1522-4d32-81b7-87f50a6f1f2a",
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.004927Z",
     "start_time": "2024-12-24T11:14:57.820378Z"
    }
   },
   "source": [
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, None], np.arange(d_model)[None, :], d_model)\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[None, ...]\n",
    "\n",
    "    return torch.FloatTensor(pos_encoding)\n",
    "\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "  cnt = 0\n",
    "  acc = 0\n",
    "\n",
    "  for data in dataloader:\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    preds = model(inputs)\n",
    "    preds = torch.argmax(preds, dim=-1)\n",
    "    #preds = (preds > 0).long()[..., 0]\n",
    "\n",
    "    cnt += labels.shape[0]\n",
    "    acc += (labels == preds).sum().item()\n",
    "\n",
    "  return acc / cnt"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [MY CODE] 마지막 토큰 반환"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YHVVsWBPQmnv",
    "outputId": "64b5790f-7649-4a47-95f8-bebe158aba4f",
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.006170Z",
     "start_time": "2024-12-24T11:14:57.828454Z"
    }
   },
   "source": [
    "def get_last_valid_embeddings(x, input_ids, pad_token_id):\n",
    "    \"\"\"\n",
    "    x: (B, S, D) shape (Transformer의 출력 혹은 embedding 결과)\n",
    "    input_ids: (B, S) shape\n",
    "    pad_token_id: 정수 (예: 0)\n",
    "\n",
    "    return: (B, D) shape\n",
    "    \"\"\"\n",
    "    # 1) PAD가 아닌 위치를 True로 표시\n",
    "    mask = (input_ids != pad_token_id)    # (B, S)  ex) True/False\n",
    "\n",
    "    # 2) 각 문장(배치)마다 유효 토큰 수\n",
    "    lengths = mask.sum(dim=1)            # (B, )  ex) [3, 5, 2, ...]\n",
    "\n",
    "    # 3) 마지막 유효 토큰 인덱스\n",
    "    last_valid_indices = lengths - 1     # (B, )\n",
    "\n",
    "    # 4) 인덱싱\n",
    "    batch_indices = torch.arange(x.size(0))  # (B, ) => [0,1,2,...,B-1]\n",
    "    last_embeddings = x[batch_indices, last_valid_indices, :]  # (B, D)\n",
    "\n",
    "    return last_embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Loss function 및 classifier output 변경\n",
    "\n",
    "1. 이진분류 -> 다중 분류\n",
    " - loss_fn = nn.CrossEntropyLoss()\n",
    " - predict -> 로짓 출력 수정\n",
    "\n",
    "2. 전체 토큰 수(Vocab Size), 이진 분류가 아니므로 ouput_size를 다양하게 시도\n",
    " - 전체 토큰 개수: 일반화에 좋음\n",
    " - 라벨 토큰 개수: 태스크가 분명한 경우\n",
    "\n",
    "3. 어디 토큰을 사용할 것인가?\n",
    " - [CLS] : x[:, 0] -> 문장 전체 의미를 요약\n",
    " - 평균, 최대 등 등\n",
    " - 문장 끝\n",
    " - 버트는 cls가 좋다고 하지만... 우리가 요하는건 뒤에만 보면 충분하지않을까?!\n",
    "\n",
    "4. 추가 전략: 중간 방식\n",
    " - 자주 등장하는 라벨(상위 N개)만 output_size로 설정\n",
    "\n",
    "5. 최적화 기법\n",
    " - 드롭아웃\n",
    " - 가중치 공유 (난 입력과 출력 사이즈가 다르므로 안씀)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.006508Z",
     "start_time": "2024-12-24T11:14:58.184999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextEndPredictor(nn.Module):\n",
    "  def __init__(self, vocab_size, d_model, n_layers, dff, output_size, dropout_rate):\n",
    "    super().__init__()\n",
    "\n",
    "    self.vocab_size = vocab_size\n",
    "    self.d_model = d_model\n",
    "    self.n_layers = n_layers\n",
    "    self.dff = dff\n",
    "\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    self.pos_encoding = nn.parameter.Parameter(positional_encoding(max_len, d_model), requires_grad=False)\n",
    "    self.layers = nn.ModuleList([TransformerLayer(d_model, d_model, dff) for _ in range(n_layers)])\n",
    "\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.dropout = nn.Dropout(self.dropout_rate)  # 드롭아웃 레이어 추가\n",
    "\n",
    "    # 이진 분류가 아니므로 토큰 개수로 변경\n",
    "    # 라벨 토큰 개수로 바꿔봄\n",
    "    self.classification = nn.Linear(d_model, output_size)\n",
    "    #self.classification.weight = self.embedding.weight  # 가중치 공유\n",
    "    # 써보려했으나 쉐잎이 다름 난 ouput_Size가 라벨임 그러나 임베딩은 vocab\n",
    "\n",
    "  def forward(self, x):\n",
    "    mask = (x == tokenizer.pad_token_id)\n",
    "    mask = mask[:, None, :]\n",
    "    seq_len = x.shape[1]\n",
    "\n",
    "    input_idx = x\n",
    "    x = self.embedding(x)\n",
    "    x = x * sqrt(self.d_model)\n",
    "    x = x + self.pos_encoding[:, :seq_len]\n",
    "\n",
    "    if self.dropout_rate > 0:\n",
    "        x = self.dropout(x) # 드롭아웃\n",
    "\n",
    "    for layer in self.layers:\n",
    "        x = layer(x, mask)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = self.dropout(x) # 드롭아웃\n",
    "\n",
    "    # 최종 선택\n",
    "    #x = x[:, 0]\n",
    "    x = get_last_valid_embeddings(x,  input_idx, pad_token_id=tokenizer.pad_token_id)\n",
    "    x = self.classification(x)\n",
    "\n",
    "    return x"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:10.006750Z",
     "start_time": "2024-12-24T11:14:58.598839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# 라벨 토큰 개수로 바꿔봄\n",
    "model = TextEndPredictor(len(tokenizer), 32, 2, 32, len(unique_labels), dropout_rate=0)\n",
    "\n",
    "lr = 0.001\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "time_list = []\n",
    "average_loss_list = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "perplexity_list = []\n",
    "\n",
    "n_epochs = 50\n",
    "start_epoch = 0\n",
    "\n",
    "\n",
    "checkpoint_path = 'checkpoint_TextEndPredictor.pth'\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    average_loss_list = checkpoint['average_loss_list']\n",
    "    train_accuracies = checkpoint['train_accuracies']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    perplexity_list = checkpoint['perplexity_list']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Loss: {average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Perplexity: {perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Train Acc: {train_accuracies[epoch]:.3f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_loss = 0.\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        model.zero_grad()\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "\n",
    "        #preds = model(inputs)[..., 0] # 이진 분류에서 로짓 추출 (기존 손실 함수는 로짓을 원함)\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time  # 에포크 실행 시간 계산\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        train_acc = accuracy(model, train_loader)\n",
    "        test_acc = accuracy(model, test_loader)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        time_list.append(epoch_time)\n",
    "        average_loss_list.append(average_loss)\n",
    "        perplexity = torch.exp(loss)  # e^Loss로 퍼플렉서티 계산\n",
    "        perplexity_list.append(perplexity)\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'average_loss_list': average_loss_list,\n",
    "        'perplexity_list':  perplexity_list,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_accuracies': test_accuracies\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Loss: {average_loss:.2f} |\"\n",
    "    f\" Perplexity: {perplexity:.2f} |\"\n",
    "    f\" Train Acc: {train_acc:.3f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f}\")\n",
    "\n",
    "# Epoch   1 | Time: 32.51 seconds | Loss: 0.75 | Perplexity: 3.23 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "\n",
    "\n",
    "# 드롭아웃\n",
    "\"\"\"\n",
    "Epoch   1 | Time: 33.34 seconds | Loss: 2.51 | Perplexity: 3.81 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "Epoch   2 | Time: 33.30 seconds | Loss: 1.92 | Perplexity: 3.41 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "Epoch   3 | Time: 33.82 seconds | Loss: 1.85 | Perplexity: 3.65 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "Epoch   4 | Time: 33.72 seconds | Loss: 1.81 | Perplexity: 3.37 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "Epoch   5 | Time: 32.41 seconds | Loss: 1.79 | Perplexity: 2.93 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "Epoch   6 | Time: 33.16 seconds | Loss: 1.77 | Perplexity: 3.03 | Train Acc: 0.558 | Test Acc: 0.564\n",
    "\"\"\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새롭게 시작~\n",
      "Epoch   1 | Time: 33.34 seconds | Loss: 2.51 | Perplexity: 3.81 | Train Acc: 0.558 | Test Acc: 0.564\n",
      "Epoch   2 | Time: 33.30 seconds | Loss: 1.92 | Perplexity: 3.41 | Train Acc: 0.558 | Test Acc: 0.564\n",
      "Epoch   3 | Time: 33.82 seconds | Loss: 1.85 | Perplexity: 3.65 | Train Acc: 0.558 | Test Acc: 0.564\n",
      "Epoch   4 | Time: 33.72 seconds | Loss: 1.81 | Perplexity: 3.37 | Train Acc: 0.558 | Test Acc: 0.564\n",
      "Epoch   5 | Time: 32.41 seconds | Loss: 1.79 | Perplexity: 2.93 | Train Acc: 0.558 | Test Acc: 0.564\n",
      "Epoch   6 | Time: 33.16 seconds | Loss: 1.77 | Perplexity: 3.03 | Train Acc: 0.558 | Test Acc: 0.564\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 52\u001B[0m\n\u001B[1;32m     50\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.\u001B[39m\n\u001B[1;32m     51\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     53\u001B[0m     model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     54\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "Cell \u001B[0;32mIn[67], line 16\u001B[0m, in \u001B[0;36mcollate_fn\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m     13\u001B[0m texts, labels \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[1;32m     15\u001B[0m   \u001B[38;5;66;03m# 라벨을 감정이 아닌 각 텍스트의 뒷자리 단어(토큰) 2개로 변경\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m   tokenizer_output \u001B[38;5;241m=\u001B[39m tokenizer(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m], truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_length\u001B[38;5;241m=\u001B[39mmax_len)\n\u001B[1;32m     17\u001B[0m   labels\u001B[38;5;241m.\u001B[39mappend(tokenizer_output\u001B[38;5;241m.\u001B[39minput_ids[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m     18\u001B[0m   texts\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mLongTensor(tokenizer_output\u001B[38;5;241m.\u001B[39minput_ids[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3016\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3014\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   3015\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 3016\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[1;32m   3017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3018\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3126\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[1;32m   3104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[1;32m   3105\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[1;32m   3106\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3123\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3124\u001B[0m     )\n\u001B[1;32m   3125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m   3127\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   3128\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   3129\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   3130\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   3131\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   3132\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   3133\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   3134\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   3135\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   3136\u001B[0m         padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m   3137\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   3138\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   3139\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   3140\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   3141\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   3142\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   3143\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   3144\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   3145\u001B[0m         split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[1;32m   3146\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3147\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3202\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3192\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[1;32m   3193\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[1;32m   3194\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   3195\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3199\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3200\u001B[0m )\n\u001B[0;32m-> 3202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encode_plus(\n\u001B[1;32m   3203\u001B[0m     text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   3204\u001B[0m     text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   3205\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   3206\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m   3207\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m   3208\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   3209\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   3210\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   3211\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   3212\u001B[0m     padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m   3213\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   3214\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   3215\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   3216\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   3217\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   3218\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   3219\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   3220\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   3221\u001B[0m     split_special_tokens\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit_special_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_special_tokens),\n\u001B[1;32m   3222\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3223\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:603\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._encode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_encode_plus\u001B[39m(\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    581\u001B[0m     text: Union[TextInput, PreTokenizedInput],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    601\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BatchEncoding:\n\u001B[1;32m    602\u001B[0m     batched_input \u001B[38;5;241m=\u001B[39m [(text, text_pair)] \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;28;01melse\u001B[39;00m [text]\n\u001B[0;32m--> 603\u001B[0m     batched_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[1;32m    604\u001B[0m         batched_input,\n\u001B[1;32m    605\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m    606\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m    607\u001B[0m         padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m    608\u001B[0m         truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m    609\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m    610\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m    611\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m    612\u001B[0m         padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[1;32m    613\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m    614\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m    615\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m    616\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m    617\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m    618\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m    619\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m    620\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    621\u001B[0m         split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[1;32m    622\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    623\u001B[0m     )\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001B[39;00m\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_overflowing_tokens:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/hanghae99_plusAI_2/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:529\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001B[0m\n\u001B[1;32m    526\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m!=\u001B[39m split_special_tokens:\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m=\u001B[39m split_special_tokens\n\u001B[0;32m--> 529\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_batch(\n\u001B[1;32m    530\u001B[0m     batch_text_or_text_pairs,\n\u001B[1;32m    531\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m    532\u001B[0m     is_pretokenized\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m    533\u001B[0m )\n\u001B[1;32m    535\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[1;32m    541\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[1;32m    543\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[1;32m    553\u001B[0m ]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
