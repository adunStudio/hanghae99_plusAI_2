{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [3주차] 심화과제: Machine translation(기계 번역)"
   ],
   "metadata": {
    "id": "sbgz49PvHhLt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# !pip install tqdm boto3 requests regex sentencepiece sacremoses datasets safetensors transformers tokenizers matplotlib torchinfo tqdm sacrebleu pandas scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Language Translation (English-French) dataset 준비"
   ],
   "metadata": {
    "id": "Cvfl_uFLIMWO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. 데이터 불러오기 & 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175621, 2)\n",
      "Index(['English words/sentences', 'French words/sentences'], dtype='object')\n",
      "  English words/sentences French words/sentences\n",
      "0                     Hi.                 Salut!\n",
      "1                    Run!                Cours !\n",
      "2                    Run!               Courez !\n",
      "3                    Who?                  Qui ?\n",
      "4                    Wow!             Ça alors !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eng_french_data = pd.read_csv('eng_-french.csv')\n",
    "print(eng_french_data.shape)\n",
    "print(eng_french_data.columns)\n",
    "print(eng_french_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. 훈련/테스트 셋 분리 (Train/Test Split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 140496\n",
      "테스트 데이터 크기: 35125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터: 80%, 테스트 데이터: 20%\n",
    "train_data, test_data = train_test_split(eng_french_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"훈련 데이터 크기: {len(train_data)}\")\n",
    "print(f\"테스트 데이터 크기: {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. T5 토크나이저 준비 & 토크나이징"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af220beb471846e1862648d910dc4f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f36198dfdae141cdb66eff506edce7e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b706931bbe25436993929ddb72a84059"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')  # t5-small, t5-base, t5-large\n",
    "\n",
    "english_column = 'English words/sentences'\n",
    "french_column  = 'French words/sentences'\n",
    "\n",
    "# 훈련 및 테스트 데이터 토크나이징\n",
    "train_encodings = tokenizer(list(train_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# 라벨(프랑스어) 토크나이징\n",
    "train_labels = tokenizer(list(train_data[french_column]), padding=True, truncation=True, max_length=512)\n",
    "test_labels = tokenizer(list(test_data[french_column]), padding=True, truncation=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 4. 데이터셋 클래스로 변환 (PyTorch Dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels['input_ids'][idx],\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(train_encodings, train_labels)\n",
    "test_dataset = TranslationDataset(test_encodings, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 5. DataLoader 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.tensor([item['attention_mask'] for item in batch])\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sacrebleu\n",
    "\n",
    "def accuracy(model, dataloader, tokenizer):\n",
    "    cnt = 0\n",
    "    acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # T5는 generate()를 사용해 예측 시퀀스를 생성\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            # 토큰 -> 텍스트로 변환 후 비교 (정확도 측정)\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            label_texts = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 문장 단위 비교 (정확히 일치하는 문장만 정답으로 간주)\n",
    "            for p, l in zip(pred_texts, label_texts):\n",
    "                if p == l:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "    return acc / cnt\n",
    "\n",
    "\n",
    "\n",
    "# BLEU 점수 계산 함수 추가\n",
    "def calculate_bleu(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            pred_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            ref_texts = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    return bleu_score\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 예측 생성\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            # 토큰 -> 텍스트 변환\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            ref_texts = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 정확도 계산 (문장 단위 비교)\n",
    "            for p, l in zip(pred_texts, ref_texts):\n",
    "                if p == l:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "            # BLEU 계산을 위한 데이터 축적\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    accuracy = acc / cnt\n",
    "\n",
    "    return accuracy, bleu_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Evaluating ...\")\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 1) Loss 계산\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 2) generate()로 텍스트 예측\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            ref_texts  = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 3) Accuracy 계산\n",
    "            for p, r in zip(pred_texts, ref_texts):\n",
    "                if p == r:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "            # 4) BLEU 계산용 데이터\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    # 평균 Loss와 Perplexity\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    ppl = torch.exp(torch.tensor(avg_loss))\n",
    "\n",
    "    # BLEU 점수\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    accuracy = acc / cnt\n",
    "\n",
    "    return avg_loss, ppl, accuracy, bleu_score\n",
    "\n",
    "def to_float_list(values):\n",
    "        \"\"\"\n",
    "        전달된 values가 None이면 None 반환.\n",
    "        list라면 각 요소를 float로 변환해 리스트로 반환.\n",
    "        (GPU Tensor인 경우 detach().cpu().item() 사용)\n",
    "        \"\"\"\n",
    "        if values is None:\n",
    "            return None\n",
    "\n",
    "        float_list = []\n",
    "        for v in values:\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                # 만약 v가 GPU 텐서라면 CPU로 이동 후 float 추출\n",
    "                float_list.append(float(v.detach().cpu().item()))\n",
    "            else:\n",
    "                # 이미 float 등의 형태라면 그대로 float 캐스팅\n",
    "                float_list.append(float(v))\n",
    "        return float_list\n",
    "\n",
    "def plot_acc(ax, title, train_accuracies, test_accuracies, label1='train', label2='test'):\n",
    "    x = np.arange(len(test_accuracies))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    train_accuracies = to_float_list(train_accuracies)\n",
    "    test_accuracies = to_float_list(test_accuracies)\n",
    "\n",
    "    if train_accuracies is not None:\n",
    "        ax.plot(x, train_accuracies, label=label1)\n",
    "    if test_accuracies is not None:\n",
    "        ax.plot(x, test_accuracies, label=label2)\n",
    "    ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] T5 모델 학습"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# T5ForConditionalGeneration 모델 설명\n",
    "\n",
    "T5는 \"인코더-디코더(Seq2Seq)\" 구조의 모델로, 텍스트 입력을 **인코딩**한 뒤 이를 **디코더**가 참고하여 새로운 텍스트를 **생성**합니다.\n",
    "Hugging Face의 `T5ForConditionalGeneration` 클래스는 이 전체 구조(인코더+디코더+Language Model Head)를 한데 묶은 것입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) shared: Embedding(32128, 512)\n",
    "\n",
    "- **shared 임베딩**: T5는 인코더와 디코더가 **같은 단어 임베딩 테이블**을 공유합니다.\n",
    "- `32128`은 T5 토크나이저의 기본 **어휘 개수**(vocab size), `512`는 **히든 차원**(d_model)을 의미합니다.\n",
    "- 입력 토큰 ID(0~32127 범위)를 512차원 벡터로 변환합니다.\n",
    "- 이 레이어는 구현상 인코더·디코더 각각에 `embed_tokens`가 있긴 하지만, 내부적으로는 동일한 파라미터(`shared`)를 참조합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) encoder: T5Stack\n",
    "\n",
    "T5의 **인코더** 부분이며, 입력 시퀀스(예: 문장)를 **문맥적(hidden state)으로 변환**하는 역할을 합니다.\n",
    "\n",
    "### (a) embed_tokens: Embedding(32128, 512)\n",
    "\n",
    "- 인코더에서 사용하는 임베딩 레이어.\n",
    "- 실제로는 위의 **`shared` 임베딩**과 동일한 파라미터를 가리킵니다.\n",
    "- 입력으로 들어온 토큰 ID를 512차원 벡터로 매핑.\n",
    "\n",
    "### (b) block: ModuleList([...])  -- 총 6개의 T5Block\n",
    "\n",
    "- **T5-Small**은 인코더 레이어가 **6개**입니다. (T5-Base는 12개, T5-Large는 24개 등)\n",
    "- 각 인코더 블록(`T5Block`)은 크게 **두 부분**으로 구성:\n",
    "  1. **Self-Attention** (자기 자신에 대한 어텐션)\n",
    "  2. **Feed-Forward** (Dense -> ReLU -> Dense)\n",
    "\n",
    "#### └─ T5Block 내부 구조\n",
    "\n",
    "- `T5LayerSelfAttention`:\n",
    "  - `T5Attention`으로 구현된 **셀프 어텐션** 모듈입니다.\n",
    "    - (q, k, v, o): 512→512 **선형 변환**.\n",
    "    - `relative_attention_bias`: T5가 사용하는 **상대적 위치 정보**(Embedding(32, 8))를 통해, 단순 절대 위치 대신 상대 거리에 따른 attention bias를 학습합니다.\n",
    "  - `layer_norm`: 레이어 정규화\n",
    "  - `dropout(p=0.1)`: 드롭아웃 적용\n",
    "\n",
    "- `T5LayerFF`:\n",
    "  - **Feed-Forward** 부분(`DenseReluDense`)\n",
    "    - wi: Linear(512 → 2048)\n",
    "    - wo: Linear(2048 → 512)\n",
    "    - act: ReLU\n",
    "    - dropout(p=0.1)\n",
    "  - `layer_norm`: 레이어 정규화\n",
    "  - `dropout(p=0.1)`: 드롭아웃 적용\n",
    "\n",
    "> 인코더의 각 레이어는 “**(Self-Attn) → (Feed-Forward)**” 순서로 진행됩니다.\n",
    "\n",
    "### (c) final_layer_norm: T5LayerNorm()\n",
    "\n",
    "- 인코더 블록을 전부 지난 뒤, 마지막으로 출력 hidden state에 대한 레이어 정규화.\n",
    "\n",
    "### (d) dropout: Dropout(p=0.1)\n",
    "\n",
    "- 인코더 출력 단에 적용되는 드롭아웃(확률 0.1).\n",
    "\n",
    "---\n",
    "\n",
    "## 3) decoder: T5Stack\n",
    "\n",
    "T5의 **디코더** 부분으로, 인코더 출력을 참고하면서 **새로운 시퀀스**(토큰)를 생성합니다.\n",
    "\n",
    "### (a) embed_tokens: Embedding(32128, 512)\n",
    "\n",
    "- 디코더 입력(이전까지 생성한 토큰, 또는 teacher forcing 시 레이블 토큰)을 512차원으로 매핑.\n",
    "- 마찬가지로 **shared 임베딩**과 동일 파라미터.\n",
    "\n",
    "### (b) block: ModuleList([...]) -- 총 6개의 T5Block\n",
    "\n",
    "- **T5-Small**에서 디코더도 **6개 레이어**를 가집니다.\n",
    "- **디코더 블록**은 인코더 블록과 달리,\n",
    "  1. Self-Attention\n",
    "  2. **Cross-Attention** (인코더-디코더 어텐션)\n",
    "  3. Feed-Forward\n",
    "  의 **3단 구조**를 가집니다.\n",
    "\n",
    "#### └─ T5Block 내부 (디코더용)\n",
    "\n",
    "1. **T5LayerSelfAttention**\n",
    "   - 디코더 **자기 자신**(이전 토큰)에 대한 어텐션.\n",
    "   - 통상적으로 **미래 토큰**은 가려지는(Causal Mask) 형태로 동작(“look-ahead mask”).\n",
    "   - `relative_attention_bias`를 통해 디코더 내에서도 상대적 위치정보 사용.\n",
    "\n",
    "2. **T5LayerCrossAttention** (EncDecAttention)\n",
    "   - 디코더가 **인코더** 출력(=Key,Value)에 대하여 어텐션을 수행.\n",
    "   - 디코더 hidden state가 Query가 되어, 인코더 hidden state(서로 다른 시퀀스 길이)를 K, V로 삼아 컨텍스트를 얻습니다.\n",
    "   - 이를 통해 번역이나 요약 등 **입력 문맥**을 참고하여 적절한 단어를 생성합니다.\n",
    "\n",
    "3. **T5LayerFF** (Feed-Forward)\n",
    "   - 인코더와 동일한 구조(`DenseReluDense`), 512→2048→512 + ReLU.\n",
    "\n",
    "- 각 서브 레이어마다 `layer_norm`, `dropout`이 적용됩니다.\n",
    "\n",
    "### (c) final_layer_norm: T5LayerNorm()\n",
    "\n",
    "- 디코더의 모든 레이어를 통과한 뒤, 최종적으로 레이어 정규화.\n",
    "\n",
    "### (d) dropout: Dropout(p=0.1)\n",
    "\n",
    "- 디코더 최종 출력에 대한 드롭아웃.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) lm_head: Linear(512 → 32128, bias=False)\n",
    "\n",
    "- 디코더 출력(최종 hidden state 512차원)을 **vocab 크기(32128)**로 매핑.\n",
    "- 각 타임스텝에서 **단어 분포**(로짓)를 산출하여, 소프트맥스하면 다음 토큰 확률을 얻게 됩니다.\n",
    "- T5는 일반적으로 출력층에 bias를 사용하지 않습니다(`bias=False`).\n",
    "\n",
    "---\n",
    "\n",
    "## 한눈에 보는 흐름\n",
    "\n",
    "1. **(shared) 임베딩**\n",
    "   - 입력 토큰 ID → (512차원 벡터)\n",
    "\n",
    "2. **인코더(encoder) 6개 레이어**\n",
    "   - (Self-Attention + Feed-Forward) x 6\n",
    "   - 최종적으로 “입력 문장 전체를 맥락적으로 요약한 **인코더 히든 스테이트**”를 출력\n",
    "\n",
    "3. **디코더(decoder) 6개 레이어**\n",
    "   - 각 레이어가 **Self-Attn**(이전 토큰들 참고) → **Cross-Attn**(인코더 히든 스테이트 참고) → **Feed-Forward**\n",
    "   - 순차적으로 토큰을 생성(학습 시 teacher forcing, 추론 시 오토리그레시브)\n",
    "\n",
    "4. **lm_head**\n",
    "   - 디코더 최종 출력을 **vocab** 크기로 변환해, **단어 분포**(로짓) 산출 → 다음 토큰 예측\n",
    "\n",
    "이렇게 T5는 “인코더-디코더 구조 + Shared Embedding + Relative Position Bias”가 핵심이며,\n",
    "다양한 시퀀스 변환 문제(번역, 요약, 문장 완성 등)를 통일된 방식(“text-to-text”)으로 처리할 수 있도록 설계되었습니다.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 간단 설명\n",
    "Shared Embedding: T5는 인코더/디코더에서 동일한 임베딩 테이블(shared)을 사용.\n",
    "\n",
    "Encoder:\n",
    "6개 블록, 각 블록은 Self-Attention과 Feed-Forward 레이어로 구성.\n",
    "입력 문장을 이해/인코딩.\n",
    "\n",
    "Decoder:\n",
    "6개 블록, 각 블록은 Self-Attention, Cross-Attention(인코더 정보 활용), Feed-Forward 레이어로 구성.\n",
    "인코더 출력 + 이전 디코딩 맥락을 기반으로 새로운 시퀀스를 생성.\n",
    "lm_head: 디코더 결과를 단어 확률 분포로 매핑해서 다음 토큰을 예측.\n",
    "\n",
    "이 구조가 인코더-디코더 기반으로 입력을 처리하고, 텍스트를 생성하는 T5의 전형적인 형태"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. pre-trained + Full Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새롭게 시작~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2196 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 72\u001B[0m\n\u001B[1;32m     69\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# T5 모델에서 직접 loss 계산\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss  \u001B[38;5;66;03m# T5는 자체적으로 loss 반환\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# 역전파 및 최적화\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1891\u001B[0m, in \u001B[0;36mT5ForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1888\u001B[0m         decoder_attention_mask \u001B[38;5;241m=\u001B[39m decoder_attention_mask\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39mfirst_device)\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;66;03m# Decode\u001B[39;00m\n\u001B[0;32m-> 1891\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1892\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1894\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1895\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1896\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1897\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1898\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1899\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1900\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1901\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1902\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1903\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1904\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1905\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1907\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m decoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1909\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1124\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1108\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39mforward,\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1121\u001B[0m         cache_position,\n\u001B[1;32m   1122\u001B[0m     )\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1124\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;66;03m# layer_outputs is a tuple with:\u001B[39;00m\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:699\u001B[0m, in \u001B[0;36mT5Block.forward\u001B[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    697\u001B[0m do_cross_attention \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_cross_attention:\n\u001B[0;32m--> 699\u001B[0m     cross_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    710\u001B[0m     hidden_states, past_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;66;03m# clamp inf values to enable fp16 training\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:629\u001B[0m, in \u001B[0;36mT5LayerCrossAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    615\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    616\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    617\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    626\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    627\u001B[0m ):\n\u001B[1;32m    628\u001B[0m     normed_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m--> 629\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEncDecAttention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnormed_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_value_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    637\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    638\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    639\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    640\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    641\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(attention_output[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    642\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m attention_output[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:553\u001B[0m, in \u001B[0;36mT5Attention.forward\u001B[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001B[39;00m\n\u001B[1;32m    552\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(scores\u001B[38;5;241m.\u001B[39mfloat(), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mtype_as(scores)\n\u001B[0;32m--> 553\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;66;03m# Mask heads if we want to\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m layer_head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/functional.py:1425\u001B[0m, in \u001B[0;36mdropout\u001B[0;34m(input, p, training, inplace)\u001B[0m\n\u001B[1;32m   1422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[1;32m   1423\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m-> 1425\u001B[0m     _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1426\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_1.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. pre-trained + Decoder Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "# 인코더 가중치 고정 (디코더만 학습)\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False  # 인코더 가중치 고정\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_2.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. none-trained T5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "config = T5Config.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration(config).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_3.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
