{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [3주차] 심화과제: Machine translation(기계 번역)"
   ],
   "metadata": {
    "id": "sbgz49PvHhLt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# !pip install tqdm boto3 requests regex sentencepiece sacremoses datasets safetensors transformers tokenizers matplotlib torchinfo pandas kagglehub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Language Translation (English-French) dataset 준비"
   ],
   "metadata": {
    "id": "Cvfl_uFLIMWO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. 데이터 불러오기 & 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175621, 2)\n",
      "Index(['English words/sentences', 'French words/sentences'], dtype='object')\n",
      "  English words/sentences French words/sentences\n",
      "0                     Hi.                 Salut!\n",
      "1                    Run!                Cours !\n",
      "2                    Run!               Courez !\n",
      "3                    Who?                  Qui ?\n",
      "4                    Wow!             Ça alors !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eng_french_data = pd.read_csv('eng_-french.csv')\n",
    "print(eng_french_data.shape)\n",
    "print(eng_french_data.columns)\n",
    "print(eng_french_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. 훈련/테스트 셋 분리 (Train/Test Split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 140496\n",
      "테스트 데이터 크기: 35125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터: 80%, 테스트 데이터: 20%\n",
    "train_data, test_data = train_test_split(eng_french_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"훈련 데이터 크기: {len(train_data)}\")\n",
    "print(f\"테스트 데이터 크기: {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. Hugging Face 토크나이저 준비 & 토크나이징"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kimhongil/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'distilbert-base-uncased')\n",
    "\n",
    "english_column = 'English words/sentences'\n",
    "french_column  = 'French words/sentences'\n",
    "\n",
    "# 훈련 및 테스트 데이터 토크나이징\n",
    "train_encodings = tokenizer(list(train_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# 라벨(프랑스어) 토크나이징\n",
    "train_labels = tokenizer(list(train_data[french_column]), padding=True, truncation=True, max_length=512)\n",
    "test_labels = tokenizer(list(test_data[french_column]), padding=True, truncation=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 4. 데이터셋 클래스로 변환 (PyTorch Dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels['input_ids'][idx],\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(train_encodings, train_labels)\n",
    "test_dataset = TranslationDataset(test_encodings, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 5. DataLoader 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
