{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [3주차] 심화과제: Machine translation(기계 번역)"
   ],
   "metadata": {
    "id": "sbgz49PvHhLt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# !pip install tqdm boto3 requests regex sentencepiece sacremoses datasets safetensors transformers tokenizers matplotlib torchinfo pandas kagglehub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Language Translation (English-French) dataset 준비"
   ],
   "metadata": {
    "id": "Cvfl_uFLIMWO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. 데이터 불러오기 & 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175621, 2)\n",
      "Index(['English words/sentences', 'French words/sentences'], dtype='object')\n",
      "  English words/sentences French words/sentences\n",
      "0                     Hi.                 Salut!\n",
      "1                    Run!                Cours !\n",
      "2                    Run!               Courez !\n",
      "3                    Who?                  Qui ?\n",
      "4                    Wow!             Ça alors !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eng_french_data = pd.read_csv('eng_-french.csv')\n",
    "print(eng_french_data.shape)\n",
    "print(eng_french_data.columns)\n",
    "print(eng_french_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. 훈련/테스트 셋 분리 (Train/Test Split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 140496\n",
      "테스트 데이터 크기: 35125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터: 80%, 테스트 데이터: 20%\n",
    "train_data, test_data = train_test_split(eng_french_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"훈련 데이터 크기: {len(train_data)}\")\n",
    "print(f\"테스트 데이터 크기: {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. T5 토크나이저 준비 & 토크나이징"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af220beb471846e1862648d910dc4f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f36198dfdae141cdb66eff506edce7e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b706931bbe25436993929ddb72a84059"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')  # t5-small, t5-base, t5-large\n",
    "\n",
    "english_column = 'English words/sentences'\n",
    "french_column  = 'French words/sentences'\n",
    "\n",
    "# 훈련 및 테스트 데이터 토크나이징\n",
    "train_encodings = tokenizer(list(train_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# 라벨(프랑스어) 토크나이징\n",
    "train_labels = tokenizer(list(train_data[french_column]), padding=True, truncation=True, max_length=512)\n",
    "test_labels = tokenizer(list(test_data[french_column]), padding=True, truncation=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 4. 데이터셋 클래스로 변환 (PyTorch Dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels['input_ids'][idx],\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(train_encodings, train_labels)\n",
    "test_dataset = TranslationDataset(test_encodings, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 5. DataLoader 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
