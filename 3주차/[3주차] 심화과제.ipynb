{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [3주차] 심화과제: Machine translation(기계 번역)"
   ],
   "metadata": {
    "id": "sbgz49PvHhLt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# !pip install tqdm boto3 requests regex sentencepiece sacremoses datasets safetensors transformers tokenizers matplotlib torchinfo tqdm sacrebleu pandas scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] Language Translation (English-French) dataset 준비"
   ],
   "metadata": {
    "id": "Cvfl_uFLIMWO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. 데이터 불러오기 & 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175621, 2)\n",
      "Index(['English words/sentences', 'French words/sentences'], dtype='object')\n",
      "  English words/sentences French words/sentences\n",
      "0                     Hi.                 Salut!\n",
      "1                    Run!                Cours !\n",
      "2                    Run!               Courez !\n",
      "3                    Who?                  Qui ?\n",
      "4                    Wow!             Ça alors !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eng_french_data = pd.read_csv('eng_-french.csv')\n",
    "print(eng_french_data.shape)\n",
    "print(eng_french_data.columns)\n",
    "print(eng_french_data.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. 훈련/테스트 셋 분리 (Train/Test Split)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 140496\n",
      "테스트 데이터 크기: 35125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터: 80%, 테스트 데이터: 20%\n",
    "train_data, test_data = train_test_split(eng_french_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"훈련 데이터 크기: {len(train_data)}\")\n",
    "print(f\"테스트 데이터 크기: {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. T5 토크나이저 준비 & 토크나이징"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af220beb471846e1862648d910dc4f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f36198dfdae141cdb66eff506edce7e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b706931bbe25436993929ddb72a84059"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')  # t5-small, t5-base, t5-large\n",
    "\n",
    "english_column = 'English words/sentences'\n",
    "french_column  = 'French words/sentences'\n",
    "\n",
    "# 훈련 및 테스트 데이터 토크나이징\n",
    "train_encodings = tokenizer(list(train_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_data[english_column]), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# 라벨(프랑스어) 토크나이징\n",
    "train_labels = tokenizer(list(train_data[french_column]), padding=True, truncation=True, max_length=512)\n",
    "test_labels = tokenizer(list(test_data[french_column]), padding=True, truncation=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 4. 데이터셋 클래스로 변환 (PyTorch Dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels['input_ids'][idx],\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(train_encodings, train_labels)\n",
    "test_dataset = TranslationDataset(test_encodings, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 5. DataLoader 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.tensor([item['attention_mask'] for item in batch])\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sacrebleu\n",
    "\n",
    "def accuracy(model, dataloader, tokenizer):\n",
    "    cnt = 0\n",
    "    acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # T5는 generate()를 사용해 예측 시퀀스를 생성\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            # 토큰 -> 텍스트로 변환 후 비교 (정확도 측정)\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            label_texts = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 문장 단위 비교 (정확히 일치하는 문장만 정답으로 간주)\n",
    "            for p, l in zip(pred_texts, label_texts):\n",
    "                if p == l:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "    return acc / cnt\n",
    "\n",
    "\n",
    "\n",
    "# BLEU 점수 계산 함수 추가\n",
    "def calculate_bleu(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            pred_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            ref_texts = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    return bleu_score\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 예측 생성\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "\n",
    "            # 토큰 -> 텍스트 변환\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            ref_texts = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 정확도 계산 (문장 단위 비교)\n",
    "            for p, l in zip(pred_texts, ref_texts):\n",
    "                if p == l:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "            # BLEU 계산을 위한 데이터 축적\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    accuracy = acc / cnt\n",
    "\n",
    "    return accuracy, bleu_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Evaluating ...\")\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 1) Loss 계산\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 2) generate()로 텍스트 예측\n",
    "            preds = model.generate(input_ids=input_ids, max_length=labels.size(1))\n",
    "            pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n",
    "            ref_texts  = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "\n",
    "            # 3) Accuracy 계산\n",
    "            for p, r in zip(pred_texts, ref_texts):\n",
    "                if p == r:\n",
    "                    acc += 1\n",
    "                cnt += 1\n",
    "\n",
    "            # 4) BLEU 계산용 데이터\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "\n",
    "    # 평균 Loss와 Perplexity\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    ppl = torch.exp(torch.tensor(avg_loss))\n",
    "\n",
    "    # BLEU 점수\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score\n",
    "    accuracy = acc / cnt\n",
    "\n",
    "    return avg_loss, ppl, accuracy, bleu_score\n",
    "\n",
    "def plot_acc(ax, title, train_accuracies, test_accuracies, label1='train', label2='test'):\n",
    "    x = np.arange(len(train_accuracies))\n",
    "    ax.set_title(title)\n",
    "    if train_accuracies is not None:\n",
    "        ax.plot(x, train_accuracies, label=label1)\n",
    "    if test_accuracies is not None:\n",
    "        ax.plot(x, test_accuracies, label=label2)\n",
    "    ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [MY CODE] T5 모델 학습"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 1. pre-trained + Full Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새롭게 시작~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2196 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 72\u001B[0m\n\u001B[1;32m     69\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# T5 모델에서 직접 loss 계산\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss  \u001B[38;5;66;03m# T5는 자체적으로 loss 반환\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# 역전파 및 최적화\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1891\u001B[0m, in \u001B[0;36mT5ForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1888\u001B[0m         decoder_attention_mask \u001B[38;5;241m=\u001B[39m decoder_attention_mask\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder\u001B[38;5;241m.\u001B[39mfirst_device)\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;66;03m# Decode\u001B[39;00m\n\u001B[0;32m-> 1891\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1892\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1894\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1895\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1896\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1897\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1898\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1899\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1900\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1901\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1902\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1903\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1904\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1905\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1907\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m decoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1909\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1124\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1108\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39mforward,\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1121\u001B[0m         cache_position,\n\u001B[1;32m   1122\u001B[0m     )\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1124\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1137\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;66;03m# layer_outputs is a tuple with:\u001B[39;00m\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:699\u001B[0m, in \u001B[0;36mT5Block.forward\u001B[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    697\u001B[0m do_cross_attention \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_cross_attention:\n\u001B[0;32m--> 699\u001B[0m     cross_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    710\u001B[0m     hidden_states, past_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;66;03m# clamp inf values to enable fp16 training\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:629\u001B[0m, in \u001B[0;36mT5LayerCrossAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    615\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    616\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    617\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    626\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    627\u001B[0m ):\n\u001B[1;32m    628\u001B[0m     normed_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m--> 629\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEncDecAttention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnormed_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_value_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    637\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    638\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    639\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    640\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    641\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(attention_output[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    642\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m attention_output[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1740\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1750\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1753\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:553\u001B[0m, in \u001B[0;36mT5Attention.forward\u001B[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001B[39;00m\n\u001B[1;32m    552\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(scores\u001B[38;5;241m.\u001B[39mfloat(), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mtype_as(scores)\n\u001B[0;32m--> 553\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;66;03m# Mask heads if we want to\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m layer_head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/hanghae99/lib/python3.10/site-packages/torch/nn/functional.py:1425\u001B[0m, in \u001B[0;36mdropout\u001B[0;34m(input, p, training, inplace)\u001B[0m\n\u001B[1;32m   1422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[1;32m   1423\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m-> 1425\u001B[0m     _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1426\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "# 인코더 가중치 고정 (디코더만 학습)\n",
    "#for param in model.encoder.parameters():\n",
    " #   param.requires_grad = False  # 인코더 가중치 고정\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_1.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 2. pre-trained + Decoder Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "# 인코더 가중치 고정 (디코더만 학습)\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False  # 인코더 가중치 고정\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_2.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ 3. none-trained T5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "config = T5Config.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration(config).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "n_epochs = 10\n",
    "start_epoch = 0\n",
    "\n",
    "time_list = []\n",
    "train_average_loss_list = []\n",
    "test_average_loss_list = []\n",
    "test_accuracies = []\n",
    "train_perplexity_list = []\n",
    "test_perplexity_list = []\n",
    "test_bleu_scores = []\n",
    "\n",
    "checkpoint_path = 'checkpoint_t5_3.pth'\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']  # 이어서 시작할 에포크\n",
    "    time_list = checkpoint['time_list']\n",
    "    train_average_loss_list = checkpoint['train_average_loss_list']\n",
    "    test_average_loss_list = checkpoint['test_average_loss_list']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    train_perplexity_list = checkpoint['train_perplexity_list']\n",
    "    test_perplexity_list = checkpoint['test_perplexity_list']\n",
    "    test_bleu_scores = checkpoint['test_bleu_scores']\n",
    "    for epoch in range(0, start_epoch):\n",
    "        print(f\"Epoch {epoch+1:3d} |\"\n",
    "        f\" Time: {time_list[epoch]:.2f} seconds |\"\n",
    "        f\" Train Loss: {train_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Loss: {test_average_loss_list[epoch]:.2f} |\"\n",
    "        f\" Test Acc: {test_accuracies[epoch]:.3f} |\"\n",
    "        f\" Train Perplexity: {train_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test Perplexity: {test_perplexity_list[epoch]:.2f} |\"\n",
    "        f\" Test BLEU Score: {test_bleu_scores[epoch]:.2f}\")\n",
    "\n",
    "    if start_epoch < n_epochs -1:\n",
    "        print(f\"이어서 시작~ {start_epoch + 1}.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"새롭게 시작~\")\n",
    "\n",
    "\n",
    "# 훈련 루프 수정\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    total_train_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):  # tqdm으로 진행 상황 시각화\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # T5 모델에서 직접 loss 계산\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # T5는 자체적으로 loss 반환\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # 한 에포크 끝난 뒤, 평균 학습 손실 & PPL\n",
    "    train_average_loss = total_train_loss / len(train_loader)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_average_loss))\n",
    "    train_average_loss_list.append(train_average_loss)\n",
    "    train_perplexity_list.append(train_perplexity)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # 정확도, BLEU 계산\n",
    "        test_average_loss, test_perplexity, test_acc, test_bleu_score = evaluate_model(model, test_loader, tokenizer)\n",
    "\n",
    "        test_average_loss_list.append(test_average_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_bleu_scores.append(test_bleu_score)\n",
    "        test_perplexity_list.append(test_perplexity)\n",
    "\n",
    "        # 에포크 실행 시간 계산\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'time_list': time_list,\n",
    "        'train_average_loss_list': train_average_loss_list,\n",
    "        'test_average_loss_list': test_average_loss_list,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'train_perplexity_list': train_perplexity_list,\n",
    "        'test_perplexity_list': test_perplexity_list,\n",
    "        'test_bleu_scores': test_bleu_scores\n",
    "\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Epoch {epoch+1:3d} |\"\n",
    "    f\" Time: {epoch_time:.2f} seconds |\"\n",
    "    f\" Train Loss: {train_average_loss:.2f} |\"\n",
    "    f\" Test Loss: {test_average_loss:.2f} |\"\n",
    "    f\" Test Acc: {test_acc:.3f} |\"\n",
    "    f\" Train Perplexity: {train_perplexity:.2f} |\"\n",
    "    f\" Test Perplexity: {test_perplexity:.2f} |\"\n",
    "    f\" Test BLEU Score: {test_bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "# 서브플롯 생성 (2행 2열)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # 2x2 서브플롯\n",
    "\n",
    "# 서브플롯 위치에 그래프 그리기\n",
    "plot_acc(axes[0, 0], \"Loss\", train_average_loss_list, test_average_loss_list)\n",
    "plot_acc(axes[0, 1], \"Perplexity\", train_perplexity_list, test_perplexity_list)\n",
    "plot_acc(axes[1, 0], \"Accuracy\", None, test_accuracies)\n",
    "plot_acc(axes[1, 1], \"BLEU Score\", None, test_bleu_scores)\n",
    "\n",
    "# 간격 조정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
